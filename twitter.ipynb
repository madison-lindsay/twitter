{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "import datetime\n",
    "import dateutil.parser\n",
    "import numpy as np\n",
    "import tweepy\n",
    "import nltk\n",
    "#nltk.download('vader_lexicon')\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "import string\n",
    "import re\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "pd.options.display.max_colwidth = 280\n",
    "stop_words = nltk.corpus.stopwords.words('english')\n",
    "stop_words.append('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def authenticate_api():\n",
    "    auth = tweepy.OAuth1UserHandler(\n",
    "        os.getenv('CONSUMER_KEY'), os.getenv('CONSUMER_SECRET'),\n",
    "        os.getenv('ACCESS_TOKEN'), os.getenv('ACCESS_SECRET')\n",
    "    )\n",
    "    api = tweepy.API(auth)\n",
    "    return api"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_dict(tweet_json):\n",
    "    tweet_dict = {}\n",
    "    for user_col in ['id', 'name', 'location', 'followers_count']:\n",
    "        tweet_dict['user_' + user_col] = [tweet_json['user'][user_col]]\n",
    "    for col in ['created_at', 'id', 'retweet_count', 'favorite_count', 'lang', 'in_reply_to_user_id', 'full_text']:\n",
    "        tweet_dict[col] = [tweet_json[col]]\n",
    "    return tweet_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_nltk_sentiment(sia, text):\n",
    "    return sia.polarity_scores(text)['compound']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_tweet(words):\n",
    "    words = words.replace('-', ' ').replace('\\n', ' ').replace('%', ' percent')\n",
    "    words = re.sub(\"RT @(.*?):\", \"\", words)  # remove RT\n",
    "    http_loc = words.find('https')\n",
    "    if http_loc > 0:\n",
    "        return words[0:http_loc-1]  # remove url\n",
    "    return words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(words):\n",
    "    tokens = re.split('\\W+', words.lower())\n",
    "    return [w for w in tokens if w not in stop_words]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_punctuation(words):\n",
    "    return \"\".join([w for w in words if w not in string.punctuation])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_df(tweets, add_sentiment=True):\n",
    "    dfs = []\n",
    "    for tweet in tweets:\n",
    "        dfs.append(pd.DataFrame(extract_dict(tweet._json)))\n",
    "    if len(dfs) == 0:\n",
    "        return pd.DataFrame()\n",
    "    df = pd.concat(dfs)\n",
    "    df['clean_tweet'] = df['full_text'].apply(lambda x: clean_tweet(x))\n",
    "    df['tokens'] = df['clean_tweet'].apply(lambda x: tokenize(remove_punctuation(x)))\n",
    "    \n",
    "    if add_sentiment:\n",
    "        sia = SentimentIntensityAnalyzer()\n",
    "        df['positivity'] = df['clean_tweet'].apply(lambda x: get_nltk_sentiment(sia, x))\n",
    "    return df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "api = authenticate_api()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets = api.home_timeline(count=100, exclude_replies=False, include_entities=False, tweet_mode='extended')\n",
    "tweet_df = get_df(tweets)\n",
    "#tweet_df\n",
    "\n",
    "# NYT = 807095"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tf idf\n",
    "def prep_inv_doc(x):\n",
    "    return tokenize(remove_punctuation(clean_tweet(x)))\n",
    "\n",
    "inv_doc = TfidfVectorizer(analyzer=prep_inv_doc)\n",
    "inv_doc_output = inv_doc.fit_transform(tweet_df['full_text'])\n",
    "id_df = pd.DataFrame(inv_doc_output.toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Methods\n",
    "* `get_retweeter_ids(id, *, count, cursor, stringify_ids)`\n",
    "* `get_retweets`\n",
    "* `get_status` \n",
    "* `search_tweets(q, *, geocode, lang, locale, result_type, count, until, since_id, max_id, include_entities)`\n",
    "    * query syntax: https://developer.twitter.com/en/docs/twitter-api/v1/rules-and-filtering/search-operators\n",
    "* `get_follower_ids(*, user_id, screen_name, cursor, stringify_ids, count)`\n",
    "    * returns 5000 at a time\n",
    "* `search_users(q, *, page, count, include_entities)`\n",
    "* `get_user(*, user_id, screen_name, include_entities)`\n",
    "* `get_blocked_ids(*, stringify_ids, cursor)` or `get_blocks(*, include_entities, skip_status, cursor)` for user objects\n",
    "* `available_trends()` and `closest_trends()`\n",
    "* `search_full_archive(label, query, *, tag, fromDate, toDate, maxResults, next)` not sure if I can access this\n",
    "* `user_timeline(*, user_id, screen_name, since_id, count, max_id, trim_user, exclude_replies, include_rts)` Returns the 20 most recent statuses posted from the authenticating user or the user specified"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Emoji positivity scores**\n",
    "* mean or median of positivity of the tweets that contain emojis\n",
    "* difficult to detect sarcasm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.020708"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "skull = api.search_tweets(\"üíÄ\", tweet_mode='extended', count=100, lang='en')\n",
    "skull_df = get_df(skull)\n",
    "skull_df['positivity'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3864837209302326"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "heart = api.search_tweets(\"‚ù§Ô∏è\", tweet_mode='extended', count=100, lang='en')\n",
    "heart_df = get_df(heart)\n",
    "heart_df['positivity'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.10854400000000002"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "puke = api.search_tweets(\"ü§Æ\", tweet_mode='extended', count=100, lang='en')\n",
    "puke_df = get_df(puke)\n",
    "puke_df['positivity'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.36406206896551724"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "war = api.search_tweets(\"war\", tweet_mode='extended', count=100, lang='en')\n",
    "war_df = get_df(war)\n",
    "war_df['positivity'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.24945656565656565"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pumpkin = api.search_tweets(\"pumpkin\", tweet_mode='extended', count=100, lang='en')\n",
    "pumpkin_df = get_df(pumpkin)\n",
    "pumpkin_df['positivity'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get_df(api.search_tweets(\"alaskan klee kai\", tweet_mode='extended', count=100, lang='en'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "330764365"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_node = api.get_user(screen_name = \"DavidCastilloAC\")  # stars reporter\n",
    "base_node.id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1225\n"
     ]
    }
   ],
   "source": [
    "followers = api.get_follower_ids(user_id=330764365)\n",
    "print(len(followers))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1214/1214 [10:21<00:00,  1.95it/s]\n"
     ]
    }
   ],
   "source": [
    "median_positivity = []\n",
    "errors = []\n",
    "no_tweets = []\n",
    "for follower in tqdm(followers):\n",
    "    try:\n",
    "        follower_tweets = get_df(api.user_timeline(\n",
    "            user_id=follower, include_rts=False, tweet_mode='extended'\n",
    "        ))\n",
    "    except:\n",
    "        errors.append(follower)\n",
    "    if follower_tweets.shape[0] == 0:\n",
    "        no_tweets.append(follower)\n",
    "        continue\n",
    "    median_positivity.append(follower_tweets['positivity'].median())\n",
    "    # second_degree = api.get_follower_ids(user_id=follower)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_user_positivity(user_id):\n",
    "    try:\n",
    "        follower_tweets = get_df(api.user_timeline(\n",
    "            user_id=user_id, include_rts=False, tweet_mode='extended'\n",
    "        ))\n",
    "    except:\n",
    "        return np.nan\n",
    "    if follower_tweets.shape[0] == 0:\n",
    "        return np.nan\n",
    "    return follower_tweets['positivity'].median()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-10-26 17:06:19.433879\n",
      "2022-10-26 17:14:26.491735\n"
     ]
    }
   ],
   "source": [
    "follower_df = pd.DataFrame({'follower': followers})\n",
    "print(datetime.datetime.now())\n",
    "follower_df['median_positivity'] = follower_df['follower'].apply(lambda x: get_user_positivity(x))\n",
    "print(datetime.datetime.now())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "follower_df[~follower_df['median_positivity'].isna()]['median_positivity'].median()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#temp_df = get_df(api.user_timeline(user_id=330764365, include_rts=False, tweet_mode='extended'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
